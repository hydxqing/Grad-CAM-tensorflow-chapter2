{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM Visualization Demo with ResNet101\n",
    "\n",
    "Requirement:\n",
    "\n",
    "* GPU Memory: 6GB or higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxq/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lxq/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxq/anaconda2/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From nets/resnet_v1.py:223: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Restoring parameters from model/resnet_v1_101.ckpt\n",
      "[[1.7806985e-04 1.4510260e-04 2.5851466e-04 ... 1.8010206e-04\n",
      "  5.3205260e-04 5.7030929e-04]\n",
      " [6.7657452e-06 4.7765738e-05 2.3799188e-05 ... 3.6346453e-06\n",
      "  1.6410889e-04 1.6715719e-03]\n",
      " [3.1226675e-04 1.9335221e-04 1.0050055e-04 ... 4.9374643e-04\n",
      "  2.6269518e-03 7.0340105e-04]]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from nets import resnet_v1\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "import utils\n",
    "\n",
    "# Create mini-batch for demo\n",
    "\n",
    "img1 = utils.load_image(\"./demo.png\", normalize=False)\n",
    "img2 = utils.load_image(\"./shihtzu_mypuppy.jpg\", normalize=False)\n",
    "img3 = utils.load_image(\"./tiger.jpg\", normalize=False)\n",
    "\n",
    "batch1_img = img1.reshape((1, 224, 224, 3))\n",
    "batch1_label = np.array([1 if i == 242 else 0 for i in range(1000)])  # 1-hot result for Boxer\n",
    "batch1_label = batch1_label.reshape(1, -1)\n",
    "\n",
    "batch2_img = img2.reshape((1, 224, 224, 3))\n",
    "batch2_label = np.array([1 if i == 155 else 0 for i in range(1000)])  # 1-hot result for Shih-Tzu\n",
    "batch2_label = batch2_label.reshape(1, -1)\n",
    "\n",
    "batch3_img = img3.reshape((1, 224, 224, 3))\n",
    "batch3_label = np.array([1 if i == 292 else 0 for i in range(1000)])  # 1-hot result for tiger\n",
    "batch3_label = batch3_label.reshape(1, -1)\n",
    "\n",
    "batch_img = np.concatenate((batch1_img, batch2_img, batch3_img), 0)\n",
    "batch_label = np.concatenate((batch1_label, batch2_label, batch3_label), 0)\n",
    "batch_size = 3\n",
    "\n",
    "# batch_img = np.concatenate((batch1_img), 0)\n",
    "# batch_label = np.concatenate((batch1_label), 0)\n",
    "# batch_size = 1\n",
    "# batch_label = batch_label.reshape(batch_size, -1)\n",
    "\n",
    "# Create tensorflow graph for evaluation\n",
    "eval_graph = tf.Graph()\n",
    "with eval_graph.as_default():\n",
    "\n",
    "    images = tf.placeholder(\"float\", [batch_size, 224, 224, 3])\n",
    "    labels = tf.placeholder(tf.float32, [batch_size, 1000])\n",
    "\n",
    "    preprocessed_images = utils.resnet_preprocess(images)\n",
    "\n",
    "    with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "        with slim.arg_scope([slim.batch_norm], is_training=False):\n",
    "            # is_training=False means batch-norm is not in training mode. Fixing batch norm layer.\n",
    "            # net is logit for resnet_v1. See is_training messing up issue: https://github.com/tensorflow/tensorflow/issues/4887\n",
    "            net, end_points = resnet_v1.resnet_v1_101(preprocessed_images, 1000)\n",
    "    prob = end_points['predictions'] # after softmax\n",
    "\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Load resnet v1 weights\n",
    "\n",
    "    # latest_checkpoint = tf.train.latest_checkpoint(\"model/resnet_v1_50.ckpt\")\n",
    "    latest_checkpoint = \"model/resnet_v1_101.ckpt\"\n",
    "    ## Optimistic restore.\n",
    "    reader = tf.train.NewCheckpointReader(latest_checkpoint)\n",
    "    saved_shapes = reader.get_variable_to_shape_map()\n",
    "    variables_to_restore = tf.global_variables()\n",
    "    for var in variables_to_restore:\n",
    "        if not var.name.split(':')[0] in saved_shapes:\n",
    "            print(\"WARNING. Saved weight not exists in checkpoint. Init var:\", var.name)\n",
    "        else:\n",
    "        # print(\"Load saved weight:\", var.name)\n",
    "            pass\n",
    "\n",
    "    var_names = sorted([(var.name, var.name.split(':')[0]) for var in variables_to_restore\n",
    "            if var.name.split(':')[0] in saved_shapes])\n",
    "    restore_vars = []\n",
    "    with tf.variable_scope('', reuse=True):\n",
    "        for var_name, saved_var_name in var_names:\n",
    "            try:\n",
    "                curr_var = tf.get_variable(saved_var_name)\n",
    "                var_shape = curr_var.get_shape().as_list()\n",
    "                if var_shape == saved_shapes[saved_var_name]:\n",
    "                    # print(\"restore var:\", saved_var_name)\n",
    "                    restore_vars.append(curr_var)\n",
    "            except ValueError:\n",
    "                print(\"Ignore due to ValueError on getting var:\", saved_var_name) \n",
    "    saver = tf.train.Saver(restore_vars)\n",
    "\n",
    "        \n",
    "        \n",
    "# Run tensorflow \n",
    "\n",
    "with tf.Session(graph=eval_graph) as sess:    \n",
    "    sess.run(init)    \n",
    "    # sess.run(tf.local_variables_initializer())\n",
    "    saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    prob = sess.run(prob, feed_dict={images: batch_img})\n",
    "    \n",
    "    print prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
